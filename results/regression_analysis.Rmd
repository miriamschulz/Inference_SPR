---
title: "SPR results: regression-based analysis of the reading times"
author: "Miriam Schulz"
date: "10/11/2022"
output:
  html_document:
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      collapse = TRUE,
                      fig.height = 6, fig.width = 9)
```


# About

This script contains an rRT analysis of the inference reading time data (SPR1) based on the rERP approach in Brouwer, Delogu & Crocker (2020). 


# Read data and preprocess

In this section:

- read in the data
- remove outliers based on 
    - SPR (word-by-word) RTs
    - context sentence RTs
- remove incorrectly answered trials (plausibility ratings)
- add log-transformed RTs
- standardize predictors

```{r include = FALSE}
# Workspace and libraries
rm(list = ls())
library(tidyverse)
library(lme4)              # for lmer()
library(lmerTest)          # for summary(lmer.model)
library(broom)             # for tidy(modeloutput)
library(gridExtra)         # for grid.arrange()
library(grid)              # for textGrob()
library(RColorBrewer)      # for color palettes
library(pander)            # for pander(df)
source("functions.R")      # custom preprocessing and helper functions
source("functions_rRT.R")  # rRT functions
options(dplyr.summarise.inform = FALSE)  # remove message in output
```

Read in data and remove fillers, practice and non-critical regions:

```{r message=FALSE}
# Read data
df <- read.csv("results_reads.csv", header = TRUE)

# Exclude filler and practice trials
df <- removeFillersPractice(df)

# Exclude non-critical regions
df <- removeRegions(df, keep.regions=-1:2)
```

Next, the raw data are visualized with histograms and QQ plots before removing outliers.

Histograms and residual plots:

```{r echo=FALSE, fig.width=10, fig.height=10}
par(mfrow=c(2,2))
# Histograms

# Histogram of RTs:
hist(df$RT,
     breaks = 50,
     col='steelblue',
     xlab = "RTs (ms)",
     main='Untransformed RTs')

# Histogram of log RTs :
hist(log(df$RT),
     breaks = 50,
     col='steelblue',
     xlab = "logRTs (ms)",
     main='Log-transformed RTs')

# QQ plots

# Untransformed RTs
qqnorm(df$RT,
       col='steelblue',
       pch=16,
       main='QQ plot of untransformed RTs')

# Log-transformed RTs
qqnorm(log(df$RT),
       col='steelblue',
       pch=16,
       main='QQ plot of log-transformed RTs')
# Save plot
ggsave("./plots/RT_hist_QQ_preDataExclusion.pdf", plot = last_plot(),
       width = 10, height = 10, dpi = 300)
par(mfrow=c(1,1))  # reset
```

## Remove SPR outliers

```{r message=FALSE}
# Optional: remove items with low accuracy in B
#df <- filter(df, ! Item %in% c(5,13,25))

# Remove outliers: SPR (word RTs) - SD
df <- removeOutliersSPR(df,
                        method = "sd",
                        sd.value = 4,
                         entire.trial = TRUE,
                        regions = -1:2)
```

Histograms and residual plots *after* removing SPR outliers:

```{r echo=FALSE, fig.width=10, fig.height=10}
par(mfrow=c(2,2))
# Histograms

# Histogram of RTs:
hist(df$RT,
     breaks = 50,
     col='steelblue',
     xlab = "RTs (ms)",
    main='Untransformed RTs')

# Histogram of log RTs :
hist(log(df$RT),
     breaks = 50,
     col='steelblue',
     xlab = "logRTs (ms)",
     main='Log-transformed RTs')

# QQ plots

# Untransformed RTs
qqnorm(df$RT,
       col='steelblue',
       pch=16,
       main='QQ plot of untransformed RTs')

# Log-transformed RTs
qqnorm(log(df$RT),
       col='steelblue',
       pch=16,
       main='QQ plot of log-transformed RTs')
# Save plot
ggsave("./plots/RT_hist_QQ_postDataExclusion.pdf", plot = last_plot(),
       width = 10, height = 10, dpi = 300)
par(mfrow=c(1,1))  # reset
```

Box-Cox plot:

```{r echo=FALSE, fig.width=4, fig.height=4}
# Boxcox plot
MASS::boxcox(df$RT ~ df$Cond)
```

Normality test (Shapiro-Wilk):

```{r}
# Untransformed RTs:
shapiro.test(filter(df, Region >= 0)$RT)

# Log-transformed RTs:
shapiro.test(log(filter(df, Region >= 0)$RT))
```

## Remove context sentence RT outliers and incorrectly answered trials

```{r fig.width=10, fig.height=5}
# Remove outliers: context sentence reading times
df <- removeOutliersContext(df, min.rt=500, max.rt=30000)

# Remove trials with incorrect plausibility ratings
df <- removeIncorrect(df)

# Visualize context sentence reading times with a histogram:
par(mfrow=(c(1,2)))
hist(
    filter(df, Region == 0)$ContextRT,
    breaks = 50,
    main = "Untransformed Context Sentence RTs",
    xlab = "Context RTs (ms)",
    col = "steelblue"
    # main = NULL
)
hist(
    log(filter(df, Region == 0)$ContextRT),
    breaks = 50,
    main = "Log-transformed Context Sentence RTs",
    xlab = "Context RTs (log-ms)",
    col = "steelblue"
)
par(mfrow=(c(1,1))) # reset
```

```{r echo=FALSE, fig.width=4, fig.height=3.5}
# Visualize average context reading times by condition:
cond.means.contextRTs <- aggregMeans(df, as.formula(ContextRT ~ Cond))
round(cond.means.contextRTs$Mean)
round(cond.means.contextRTs$SD)

p <-
  cond.means.contextRTs %>% 
  ggplot(aes(x = Cond, y = Mean, fill=Cond)) + 
  geom_bar(stat='identity', width=0.8) + 
  geom_errorbar(
    aes(ymin = Mean - SE, ymax = Mean + SE),
    width = 0.15,
    linewidth = 0.3
  ) +
  ylim(0, 3000) +
  xlab("Condition") +
  ylab("RT (ms)") +
  scale_fill_manual(values = c("cornflowerblue", "chartreuse3",
                               "tomato2", "darkgoldenrod1")) +
  theme_minimal() +
  theme(legend.position="None",
        text = element_text(size = 13))
filename <- paste0("./plots/", "context_RT.pdf")
ggsave(filename, plot = p, width = 3, height = 3)
p + ggtitle("Context sentence RT by condition")
```

## Further preprocessing: transformations etc.

In this subsection: 

- Rename variables
- Transform to factor when necessary
- Combine Inference+Coherence ratings into a new combined predictor with PCA, extracting the first component
- add precritical reading times as predictors 
- add log-transformed versions of the reading times (the SPR RT (DV) as well as predictors (IVs))
- standardize the predictors

```{r message=FALSE}
# Rename variables 
rating_colnames <- str_remove(names(df), "Rating")
names(df) <- rating_colnames
df <- rename(df, ProdNorms = ProductionPercentage)

# Transform variables to factors
df$Cond <- as.factor(df$Cond)
df$Item <- as.factor(as.numeric(as.character(df$Item)))
df$Subject <- as.factor(as.numeric(as.character(df$Subject)))

# Transform the binary plausibility predictor to numeric, then to factor
df$Plausible <- as.factor(ifelse(df$Plausible == "Yes", 1, 0))

# Better: combine the predictors using PCA
pca_fit <- stats::prcomp(dplyr::select(df, Inference, Coherence), scale=TRUE)
df$InfCoPCA <- pca_fit$x[,1]

# Extract precritical RT -1 and add to df:
df.precrit1 <- filter(df, Region == -1) %>% 
  dplyr::select(Item, Cond, Subject, RT) %>% 
  rename(RT_precrit1 = RT)
df <- merge(df, df.precrit1, by = c("Item", "Cond", "Subject"))

# Extract precritical RT -2 and add to df:
#df.precrit2 <- filter(df, Region == -2) %>% 
#  dplyr::select(Item, Cond, Subject, RT) %>% 
#  rename(RT_precrit2 = RT)
#df <- merge(df, df.precrit2, by = c("Item", "Cond", "Subject"))

# Add target length 
df <- df %>% mutate(Length = nchar(Target))

# Add log-transformed variables (DV + IVs)
df$logRT <- log(df$RT)
df$logRT_precrit1 <- log(df$RT_precrit1)
#df$logRT_precrit2 <- log(df$RT_precrit2)
df$logProdNorms <- log(df$ProdNorms)
df$logAssociation <- log(df$Association)
df$logInference <- log(df$Inference)
df$logCoherence <- log(df$Coherence)
#df$logInfCoPCA <- log(df$InfCoPCA)

# Order df by Region
df <- arrange(df, Region)

# Invert predictor scales 
#df$AssociationRating <- df$AssociationRating - 7
#df$CoherenceRating <- df$CoherenceRating - 7
#df$InferenceRating <- df$InferenceRating - 7

# Scale predictors (careful: needs to be performed AFTER removing data)
# Note: predictors can be scaled here instead of in the per-region dfs, since 
# predictors are identical in each region 
df <- scalePredictors(
 df,
 c(
   "ProdNorms",
   "Association",
   "Inference",
   "Coherence",
   "InfCoPCA",
   "RT_precrit1",
   #"RT_precrit2",
   "logRT_precrit1",
   #"logRT_precrit2",
   "Length"
 )
)

#str(df)
```


# Observed RTs

## Mean RTs by condition for each region of interest

```{r echo = FALSE}
# Summary:
# Untransformed RTs
pander::pander(df %>%
                 group_by(Cond, Region) %>%
                 summarize(Mean = mean(RT)) %>%
                 spread(Region, Mean) %>%
                 mutate_if(is.numeric, round),
               caption = "Untransformed RTs")
# Log-transformed RTs
pander::pander(df %>%
                 group_by(Cond, Region) %>%
                 summarize(Mean = mean(logRT)) %>%
                 spread(Region, Mean),
               caption = "Log-transformed RTs")
# With SD and SE:
pander::pander(aggregMeans(df,
                  as.formula(RT ~ Region + Cond),
                  round.data = TRUE) %>%
                 mutate_if(is.numeric, round),
               caption="Untransformed RTs (long format) with SD+SE")
```

## Plots

### RTs by region and condition 

```{r echo = FALSE, fig.width=6.5, fig.height=4.5}
#df <- filter(df, !Item %in% c(5, 13, 25))
p1 <- plotSPR(df, "RT", "RT", c(260, 325))
p2 <- plotSPR(df, "logRT", "logRT", c(5.52,5.73))
ggsave("./plots/observed_RTs.pdf", p2,
       width = 3.2, height = 3.5, dpi=300)
grid.arrange(p1+ggtitle("Untransformed RTs"),
             p2+ggtitle("Log-transformed RTs"),
             ncol=2,
             top = textGrob("Observed reading times",
                            gp=gpar(fontsize=14, fontface=2)))
```


### Density plot: variation across regions 

Check the *range* of the reading times in the critical regions (i.e. the spread of the variation).

Larger ranges implies that the residuals will be larger due to the increased amount of variation in that region.

```{r echo = FALSE, warning = FALSE, fig.width=6, fig.height=4}
spread.color.palette <- c("-1" = "rosybrown1",
                          "0" = "black",
                          "1" = "deeppink2", 
                          "2" = "purple3")
# Density plot
p.spread <- df %>%
  filter(Region %in% -1:2) %>%
  ggplot(aes(
    x = logRT,
    group = Region,
    linetype = factor(Region),
    color = factor(Region)
  )) +
  geom_density(adjust = 0.8,
               linewidth = 1,
               key_glyph = draw_key_smooth) +
  #xlim(c(0, 1000)) +
  ylab("Density") +
  scale_color_manual("Region",  # Legend title
                     values = spread.color.palette,
                     labels = c("Pre-critical", "Critical",
                                "Spillover", "Post-spillover")) +
  scale_linetype_manual(
    "Region",  # Legend title
    values = c("dotdash", "solid", "dashed", "dotted"),
    labels = c("Pre-critical", "Critical",
               "Spillover", "Post-spillover")
  ) +
  theme_minimal()

ggsave("./plots/spread_RT.pdf", p.spread,
       width = 5, height = 3.5, dpi=300)

p.spread + ggtitle("Spread of RTs by Region")
```

The peaks are less pronounced for the critical and first spillover version; the critical region has the least steep rightgoing tail.


### Task effect: decreasing RTs

Check the presence of a task effect (decreasing RTs over the course of the experiment) by subject.

The precritical region RTs are used here since target words differ in length from trial to trial, while the precritical word is always a determiner.

**Method 1: RT ~ Block**

Aggregate mean RT ~ Block:

```{r echo = FALSE, fig.width=4, fig.height=3}
mean.RT.block <- aggregMeans(filter(df, Region==-1),
                             as.formula(RT ~ Block))

p.taskeffect <- mean.RT.block %>%
  ggplot(aes(x = Block, y = Mean, color = Block)) +
  geom_point(size = 5,
             shape = "cross") +
  geom_errorbar(aes(ymin = Mean - SE,
                    ymax = Mean + SE),
                width = 0.2,
                linewidth = 0.3) +
  xlab("Time (Block)") +
  ylab("RT (ms)") +
  scale_colour_brewer(palette="Dark2")+
  theme_minimal()

ggsave("./plots/taskeffect.pdf", p.taskeffect,
       width = 4, height = 3, dpi=300)

p.taskeffect + ggtitle("Mean RT by block position")
```


**Method 2: RT ~ TrialNumber**

```{r echo = FALSE, message = FALSE, fig.width=7, fig.height=4}
mean.RT.trialnum <- df %>% 
  filter(Region == -1) %>% 
  group_by(TrialNum) %>% 
  summarize(MeanRT = mean(RT)) %>% 
  data.frame()

mean.RT.trialnum %>% 
  ggplot(aes(x=TrialNum, y=MeanRT)) + 
  geom_smooth(method = 'lm', se=TRUE, alpha = .2, color='steelblue') + 
  geom_line(color='steelblue') + 
  #ylim(c(0,350)) + 
  xlab("Time (trial position)") + 
  ylab("RT (ms)") +
  theme_minimal() +
  ggtitle("Mean RT by trial position")
```

```{r include = FALSE, fig.width=7, fig.height=4}
df %>%
  filter(Region == -1) %>% 
  ggplot(aes(x = TrialNum, y = RT, color=Subject, group=Subject)) + 
  #geom_point(size=1.5, shape="cross", alpha = 0.5) + 
  geom_smooth(method = 'lm', size = 0.5, se=TRUE, alpha = .2, aes(fill=Subject)) +
  #geom_smooth(method = 'lm', se=TRUE, alpha = .2, aes(x = TrialNum, y = RT)) +
  ggtitle("RT by Subject + trial number") +
  theme_minimal() +
  theme(legend.position = "None")
```


# Models 

## Define parameters

Define general parameters:

- regions of interest to model
- untransformed or log-transformed RTs
- based on RT unit (ms or log ms): ranges for the plot y-axis
- which kind of model to run:
  - "lm": simple LM
  - "lm.by.subj": by-subject LMs
  - "lmer": LMER

```{r}
regions <- -1:2
log.RTs <- TRUE
m.type = "lmer"

if (log.RTs == TRUE) {
  DV <- "logRT"
  precrit1 <- "logRT_precrit1"
  precrit2 <- "logRT_precrit2"
  y.unit <- "Log RT"
  y.range <- c(5.52, 5.72)
  y.range.res <- c(-0.07, 0.07)
} else {
  DV <- "RT"
  precrit1 <- "RT_precrit1"
  precrit2 <- "RT_precrit2"
  y.unit <- "RT (ms)"
  y.range <- c(260, 320)
  y.range.res <- c(-20, 20)
}
```


## Traditional analysis

**TODO:** use condition instead of individual predictors for the traditional analysis

```{r}
# Split data into different data frames for each region 
precrit <- filter(df, Region==-1)
crit <- filter(df, Region==0)
spill1 <- filter(df, Region==1)
spill2 <- filter(df, Region==2)

f1 <- as.formula(logRT ~ Association + InfCoPCA + logRT_precrit1 + (1|Subject) + (1|Item))
summary(lmer(f1, data=crit))
summary(lmer(f1, data=spill1))
summary(lmer(f1, data=spill2))

f2 <- as.formula(logRT ~ Association + Inference + logRT_precrit1 + (1|Subject) + (1|Item))
summary(lmer(f2, data=crit))
summary(lmer(f2, data=spill1))
summary(lmer(f2, data=spill2))

f3 <- as.formula(logRT ~ Association + Coherence + logRT_precrit1 + (1|Subject) + (1|Item))
summary(lmer(f3, data=crit))
summary(lmer(f3, data=spill1))
summary(lmer(f3, data=spill2))

f4 <- as.formula(logRT ~ Association + Coherence + logRT_precrit1 + Association*Coherence + (1|Subject) + (1|Item))
summary(lmer(f4, data=crit))
summary(lmer(f4, data=spill1))
summary(lmer(f4, data=spill2))

f5 <- as.formula(logRT ~ Association + Coherence + logRT_precrit1 + Association*Coherence + Block + (1|Subject) + (1|Item))
summary(lmer(f5, data=crit))
summary(lmer(f5, data=spill1))
summary(lmer(f5, data=spill2))

f6 <- as.formula(logRT ~ Association + Coherence + logRT_precrit1 + Association*Coherence + TrialNum + (1|Subject) + (1|Item))
summary(lmer(f6, data=crit))
summary(lmer(f6, data=spill1))
summary(lmer(f6, data=spill2))

f7 <- as.formula(logRT ~ Association + Coherence + logRT_precrit1 + Association*Coherence + TrialNum + Length + (1|Subject) + (1|Item))
summary(lmer(f7, data=crit))
summary(lmer(f7, data=spill1))
summary(lmer(f7, data=spill2))
```


## Intercept (baseline) LM model

Following the logic of Brouwer et al. (2020), the analysis starts with a baseline model of the variance in the signal. 
The baseline model assumes that no factors were manipulated and that all trials belong to the same condition. 
Therefore, the resulting estimate for each trial in a given region will simply be the average over all trials (and conditions; equivalent to an intercept-only model) in that region. 

Unlike in rERP modeling, different models do not need to be fitted for different electrodes, but like in rERP modeling, different models will be fitted for each subject ($N=40$) and time point (i.e., region, $N=4$: pre-critical region, critical region, post-critical region 1, post-critical region 2), yielding a total of $40 * 4 = 160$ models.

However, here we first start with an even simpler baseline model averaging over subjects.

```{r, results = FALSE, echo = FALSE, fig.width=9, fig.height=5}
# Model formula
m.formula <- as.formula(paste0(DV, " ~ 1"))

# Run model(s) and generate plots
modelAndPlot("Intercept",
             m.formula,
             df,
             "lm.by.subj",
             regions,
             DV,
             y.unit,
             y.range,
             y.range.res,
             coef.plot = FALSE)

# Run model(s) and generate plots
m.formula <- as.formula(paste0(DV, " ~ 1 + (1|Subject) + (1|Item)"))
modelAndPlot("Intercept",
             m.formula,
             df,
             m.type,
             regions,
             DV,
             y.unit,
             y.range,
             y.range.res,
             coef.plot = FALSE)

#TODO: 
# - remove top title for saved plot
# - make legend larger but keep only 1 legend per grid.arrange
# - begin from building the full model and then eliminate predictors
```

Full model (no interaction):

```{r fig.width=12, fig.height=5}
m.formula <- as.formula(paste0(DV, " ~ 1 + Association + Coherence + logRT_precrit1"))
modelAndPlot("Intercept",
             m.formula,
             df,
             "lm.by.subj",
             -1:2,
             DV,
             y.unit,
             y.range,
             y.range.res,
             coef.plot = FALSE)

m.formula <- as.formula(paste0(DV, " ~ 1 + Association + Coherence + 
   logRT_precrit1 + (1 | Subject) + (1 | Item)"))
modelAndPlot("Intercept",
             m.formula,
             df,
             m.type,
             regions,
             DV,
             y.unit,
             y.range,
             y.range.res,
             coef.plot = FALSE)
```

Full model with interaction:

```{r fig.width=12, fig.height=5}
m.formula <- as.formula(paste0(DV, " ~ 1 + Association + Coherence + 
                               logRT_precrit1 +  Association*Coherence"))
modelAndPlot("Intercept",
             m.formula,
             df,
             "lm.by.subj",
             -1:2,
             DV,
             y.unit,
             y.range,
             y.range.res,
             coef.plot = FALSE)

m.formula <- as.formula(paste0(DV, " ~ 1 + Association + Coherence + 
   logRT_precrit1 +  Association*Coherence +(1 | Subject) + (1 | Item)"))
modelAndPlot("Intercept",
             m.formula,
             df,
             m.type,
             regions,
             DV,
             y.unit,
             y.range,
             y.range.res,
             coef.plot = FALSE)
```

Include Block or TrialNum as predictor:

```{r}
m.formula <- as.formula(paste0(DV, " ~ 1 + Association + Coherence + 
   logRT_precrit1 + Block +
   Association*Coherence + (1 | Subject) + (1 | Item)"))
modelAndPlot("Intercept",
             m.formula,
             df,
             m.type,
             regions,
             DV,
             y.unit,
             y.range,
             y.range.res,
             coef.plot = FALSE)

m.formula <- as.formula(paste0(DV, " ~ 1 + Association + Coherence + 
   logRT_precrit1 + TrialNum +
   Association*Coherence + (1 | Subject) + (1 | Item)"))
modelAndPlot("Intercept",
             m.formula,
             df,
             m.type,
             regions,
             DV,
             y.unit,
             y.range,
             y.range.res,
             coef.plot = FALSE)

f7 <- as.formula(logRT ~ Association + Coherence + logRT_precrit1 + Association*Coherence + TrialNum + Length + (1|Subject) + (1|Item))
modelAndPlot("Intercept",
             f7,
             df,
             m.type,
             regions,
             DV,
             y.unit,
             y.range,
             y.range.res,
             coef.plot = FALSE)
```


## Incremental rRT analysis

In the following analysis, each observed RT is replaced with an estimated RT obtained from a linear mixed effects model (using the lmer function from the lme4 package, Bates et al. 2015).

Beyond analyzing the estimated RTs, this approach allows to examine how the estimates change as individual predictors are controlled for (by setting them to their grand mean value across conditions).
This method provides insight into how individual predictors -- corresponding to specific properties of the stimulus presented at trial $i$ -- combine at a latent level in each trial to form the resulting observed RT.
Concretely, the signal for a specific stimulus at each trial $i$ is broken down into a weighted sum of the individual predictors, plus the noise term $\epsilon_i$:

$$
y_i = \beta_1 x_{1i} + \beta_2 x_{2i} +  ... + \epsilon_i = \sum_{j = 1}^N \beta_j x_{ji} + \epsilon_i
$$

where 

- $\beta_j$ stands for the coefficient estimate for an individual predictor $j$;
- $x_{ji}$ stands for the stimulus property for predictor $j$ at trial $i$;
- $\epsilon_i$ stands for the noise in trial $i$

and the goal of the estimation process is to find the set of $\beta_j$'s that minimizes $\epsilon_i$ across trials, given the stimulus properties $x_{ji}$.

**TODO:** add lmer-adjusted formula with random effects

The impact of each predictor in each region of interest can be analyzed by inspecting the change in the residual error ensuing when the predictor is controlled for (i.e., set to its mean value -- which in the present analysis corresponds to setting it to zero, given that predictors were standardized to have a mean of $0$ and a standard deviation of $1$).
More precisely, an increase in residual error when controlling for a specific predictor in a model (and correspondingly a larger deviation of the estimated RTs from the observed RTs) indicates that this predictor is critical for reducing the error in that region.
This provides a quantitative measure of goodness of model fit that allows to compare different models in which the impact of the individual predictors can be isolated (where closer approximation of $\epsilon$ to $0$ means better fit).

Finally, the effect structure of the observed RTs vs. that of the estimated rRTs can be compared using statistical analysis of variance techniques:
First, anova can be run on the estimated rRTs.
Second, anova can be run to compare observed RTs and estimated rRTs with type as a between-subjects factor, where no significant effect of type is expected if the rRTs adequately capture the variance in the observed data.

In the following, the different regions are analyzed as independent models following the hypothesis that different predictors will have different effects in different regions. 
To control for baseline offset, the precritical region is always added as a predictor in the models for the different regions. 
Note that inclusion of the precritical RTs in the model for the precritical region itself leads to perfect estimates with a singular fit warning and no remaining error, as is to be expected. 
(TODO: do not plot precritical region at all? This should be the same in all plots though!)

### Step 1: Assess the impact of individual factors

In this section, the fit of the individual predictors is assessed in isololation. 

Aims:

A) determine the impact of log-transformations of the predictors (for the following predictors: Association, Inference, Coherence, InfCoPCA)
B) compare the collinear predictors Inference, Coherence and InfCoPCA (first PCA component combining Inference+Coherence)

Method: 

- compute individual models for each predictor, using a subset of the experimental conditions for which there is variation in this predictor while variation is minimized among the other predictors
- compare residual plots, AIC and BIC for the different models for each predictor

A) Inspect residual plots for the same predictor untransformed vs. logtransformed

A.1) For Association, use conditions A and B, where Inference/Coherence are both high:


```{r}
knitr::knit_exit()
```


```{r}
df.AB <- filter(df, Cond %in% c("A", "B"))
f1 <- as.formula(get(DV) ~ Cond + Region)
modelAndPlot(
  as.formula,
             df,
             m.type,
             regions,
             DV, 
             y.unit, 
             y.range, 
             y.range.res)
```




## Models with a single predictor 

### Intercept + binary Plausibility LM

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Plausible"))
modelAndPlot("Intercept+Plausibility",
             m.formula,
             df,
             m.type,
             regions,
             DV, 
             y.unit, 
             y.range, 
             y.range.res)
```


### Intercept + Association LM

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Association"))
modelAndPlot(
  "Intercept+Association",
  m.formula,
  df,
  m.type,
  regions,
  DV,
  y.unit,
  y.range,
  y.range.res
)
```


### Intercept + Coherence LM

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Coherence"))
modelAndPlot(
  "Intercept+Coherence",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)
```


### Intercept + Inference LM

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Inference"))
modelAndPlot(
  "Intercept+Inference",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)
```


### Intercept + PrecritRT 1 LM

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + ", paste0(precrit1)))
modelAndPlot(
  "Intercept+PrecritRT1",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)
```


### Intercept + PrecritRT 2 LM

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + ", precrit2))
modelAndPlot(
  "Intercept+PrecritRT2",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)
```



## Models with more than 1 predictor

### Intercept + Association + Coherence 

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Association + Coherence"))
modelAndPlot(
  "Intercept+Association+Coherence",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)
```


### Intercept + Association + Coherence + Precrit_RT1

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Association + Coherence + ", precrit1))
modelAndPlot(
  "Intercept+Association+Coherence+Precrit1",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)
```


### Intercept + Association + Inference + Precrit_RT1

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Association + Inference + ", precrit1))
modelAndPlot(
  "Intercept+Association+Inference+Precrit1",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)
```


### Intercept + Association + Coherence + Precrit_RT2

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Association + Coherence + ", precrit2))
modelAndPlot(
  "Intercept+Association+Coherence+Precrit2",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)
```


### Intercept + Association + Coherence + Precrit_RT1 + Precrit_RT2 + Plausible

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV,
                               " ~ 1 + Association + Coherence + Plausible + ",
                               precrit1, " + ", precrit2))
modelAndPlot(
  "Intercept+Association+Coherence+Precrit1&2+Plausibility",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)
```



## Models with interaction terms

### Association * Coherence

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ Association * Coherence "))
modelAndPlot(
  "Association*Coherence",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)
```

### Association * Coherence * precrit1

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ Association * Coherence * ", precrit1))
modelAndPlot(
  "Association*Coherence*Precrit1",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)
```

### Association * Coherence * precrit2

```{r, results = FALSE, fig.height = 6, fig.width = 9}
m.formula <- as.formula(paste0(DV, " ~ Association * Coherence * ", precrit2))
modelAndPlot(
  "Association*Coherence*Precrit2",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)
```

### Intercept + Association * Coherence * precrit1 * precrit2

```{r, results = FALSE, fig.height = 6, fig.width = 9}
m.formula <- as.formula(paste0(DV, " ~ Association * Coherence * ",
                               precrit1, " * ", precrit2))
modelAndPlot(
  "Association*Coherence*Precrit1*Precrit2",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res,
  coef.plot = FALSE  # since too many coefficients 
)
```


### Intercept + Association + Coherence + Association : Coherence + RT_Precrit1

```{r, results = FALSE}
m.formula <- as.formula(paste0(
  DV,
  " ~ Association + Coherence + Association:Coherence + ",
  precrit1
))

modelAndPlot(
  "Intercept+Association+Coherence+Association:Coherence+Precrit1",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)


model.output <- runModels(df, m.type, m.formula, regions = regions)
p <- plotSPR(model.output, DV, "Observed RTs", y.unit, y.range)
filename <- paste0("./plots/", DV, "_", "Observed_only", ".png")
ggsave(filename, plot = p, width = 5, height = 4)
```


## lmer 


### Intercept + Coherence, Random Intercepts 

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Coherence +
                              (1 | Item) + (1 | Subject)"))
modelAndPlot(
  "Intercept+Coherence",
  m.formula,
  df, "lmer", regions, DV,
  y.unit, y.range, y.range.res
)
```

### Intercept + Association + Coherence, Random Intercepts 

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Association + Coherence +
                              (1 | Item) + (1 | Subject)"))
modelAndPlot(
  "Intercept+Association+Coherence",
  m.formula,
  df, "lmer", regions, DV,
  y.unit, y.range, y.range.res
)
```


### Intercept + Association + Coherence + Precrit1, Random Intercepts 

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Association + Coherence + ",
                               precrit1,
                              " + (1 | Item) + (1 | Subject)"))
modelAndPlot(
  "Intercept+Association+Coherence+Precrit1",
  m.formula,
  df, "lmer", regions, DV,
  y.unit, y.range, y.range.res
)
```


### Intercept + Association + Coherence + Precrit1 + Association:Coherence, Random Intercepts 

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Association + Coherence + Association:Coherence + ",
                               precrit1,
                              " + (1 | Item) + (1 | Subject)"))
modelAndPlot(
  "Intercept+Association+Coherence+Association:Coherence+Precrit1",
  m.formula,
  df, "lmer", regions, DV,
  y.unit, y.range, y.range.res
)
```

### Intercept + Association*Coherence*Precrit1, Random Intercepts 

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Association* Coherence * ",
                               precrit1,
                              " + (1 | Item) + (1 | Subject)"))
modelAndPlot(
  "Association*Coherence*Precrit1",
  m.formula,
  df, "lmer", regions, DV,
  y.unit, y.range, y.range.res
)
```



## Setting predictors to zero

```{r}
m.formula <- as.formula(paste0(DV, " ~ 1 + Association + Coherence +",
                               precrit1))

m.formula <- as.formula(paste0(
  DV,
  " ~ Association + Coherence + Association:Coherence + ",
  precrit1
))

m <- runModels(df,
               "lm.by.subj",
               m.formula,
               regions)

# Set predictors to zero

#TODO: do this on the full model (here, only performed on the model without an interaction term)

# Plot only the intercept
m$InterceptOnly <- m$`Coef_(Intercept)`
plotSPR(m, "InterceptOnly", "Estimates: Intercept only", y.unit, y.range)

# Add association only
m$InterceptAssoc <- m$`Coef_(Intercept)` + m$Association*m$Coef_Association 
plotSPR(m, "InterceptAssoc", "Estimates: Intercept+Assoc", y.unit, y.range)

# Add coherence only
m$InterceptCoherence <- m$`Coef_(Intercept)` + m$Coherence*m$Coef_Coherence
plotSPR(m, "InterceptCoherence", "Estimates: Intercept+Coherence", y.unit, y.range)

# Add precritical only 
m$InterceptPrecrit1 <- m$`Coef_(Intercept)` + m$logRT_precrit1*m$Coef_logRT_precrit1
plotSPR(m, "InterceptPrecrit1", "Estimates: Intercept+Precrit1", y.unit, y.range)

# Add everything except association 
m$InterceptCoherencePrecrit1 <- m$`Coef_(Intercept)` + m$Association*0  + m$Coherence*m$Coef_Coherence + m$logRT_precrit1*m$Coef_logRT_precrit1
plotSPR(m, "InterceptCoherencePrecrit1", "Estimates: Intercept+Coherence+Precrit1", y.unit, y.range)

# Add everything except coherence 
m$InterceptAssocPrecrit1 <- m$`Coef_(Intercept)` + m$Association*m$Coef_Association  + m$Coherence*0 + m$logRT_precrit1*m$Coef_logRT_precrit1
plotSPR(m, "InterceptAssocPrecrit1", "Estimates: Intercept+Association+Precrit1", y.unit, y.range)

# Sanity check: full model 
m$Full <- m$`Coef_(Intercept)` + m$Association*m$Coef_Association  + m$Coherence*m$Coef_Coherence + m$logRT_precrit1*m$Coef_logRT_precrit1 +  m$Association*m$Coherence*m$`Coef_Association:Coherence`
plotSPR(m, "Full", "Estimates: Full model", y.unit, y.range)
```


## Models with ProductionNorms as predictor

### Intercept + ProdNorms

```{r, results = FALSE}
# Model formula
m.formula <- as.formula(paste0(DV, " ~ 1 + Association + Coherence + ", precrit2))

# Run a model for each region
m.intercept.assoc.coherence.precrit2 <- runModels(df, m.type, m.formula, regions = regions)

# Generate plots
p <- generatePlots(m.intercept.assoc.coherence.precrit2,
                   "Intercept+Association+Coherence+Precrit2", m.type, DV,
                   y.unit, y.range, y.range.res)
```




```{r, results = FALSE, eval = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Coherence + (1 + Coherence | Item) +
                               (1 + Coherence | Subject)"))


m.lmer <- lmer(RT ~ 1 + Association + Coherence + (1 + Coherence| Subject) + (1 +Coherence | Item),
           data = filter(df, Region == 0))
summary(m.lmer)


#TODO add interaction term 
#TODO: set individual predictors to zero from full model and inspect/plot (plot estimate vs. residual)
#TODO: check if lmer fixed eff coefs are comparable to lm fixed eff coefs 
#TODO loop over subjects, individual model per subject, then average 


# Model output 
fixef(m.lmer)  # fixed effects 
summary(m.lmer)$coefficients
coef(m.lmer)   # subject/item estimates
ranef(m.lmer)  # deviation of subject/item from main effect

# Subject estimates with coef() are equal to main effect + ranef():
est <- ranef(m.lmer)$Subject
cf <- coef(m.lmer)$Subject
est$"(Intercept)" + fixef(m.lmer)[[1]] == cf$"(Intercept)"


  
subj.coef <- coef(m.lmer)$Subject
item.coef <- coef(m.lmer)$Item
subj.ranef <- ranef(m.lmer)$Subject
item.ranef <- ranef(m.lmer)$Item

mean(subj.coef$Coherence)
mean(item.coef$Coherence)
range(subj.coef$Coherence)
range(item.coef$Coherence)
round(mean(subj.ranef$Coherence), 5)
round(mean(item.ranef$Coherence), 5)

mean(subj.coef[, 1])
mean(item.coef[, 1])
range(subj.coef[, 1])
range(item.coef[, 1])
round(mean(subj.ranef[, 1]), 5)
round(mean(item.ranef[, 1]), 5)

coef(summary(m.lmer))
```


Improved version: 

```{r, fig.height = 7, fig.width = 14}
m.formula <- as.formula(paste0(
  DV,
  " ~ Association + Coherence + Association:Coherence + ",
  precrit1
))

m <- runModels(df,
               "lm.by.subj",
               m.formula,
               regions)

# Set predictors to zero: start with all zero except the intercept,
# then add in more predictors

# Plot only the intercept
m$InterceptOnly <- m$`Coef_(Intercept)`
plotSPR(m, "InterceptOnly", "Estimates: Intercept only", y.unit, y.range)

# Add association only
m$InterceptAssoc <- m$`Coef_(Intercept)` + m$Association*m$Coef_Association 
plotSPR(m, "InterceptAssoc", "Estimates: Intercept+Assoc", y.unit, y.range)

# Add coherence only
m$InterceptCoherence <- m$`Coef_(Intercept)` + m$Coherence*m$Coef_Coherence
plotSPR(m, "InterceptCoherence", "Estimates: Intercept+Coherence", y.unit, y.range)

# Add precritical only 
m$InterceptPrecrit1 <- m$`Coef_(Intercept)` + m$logRT_precrit1*m$Coef_logRT_precrit1
plotSPR(m, "InterceptPrecrit1", "Estimates: Intercept+Precrit1", y.unit, y.range)

# Add everything except association 
m$InterceptCoherencePrecrit1Interaction <- m$`Coef_(Intercept)` + m$Association*0 + m$Coherence*m$Coef_Coherence + m$logRT_precrit1*m$Coef_logRT_precrit1 + m$Association*m$Coherence*m$`Coef_Association:Coherence`
p1 <- plotSPR(m, "InterceptCoherencePrecrit1Interaction", "Estimates: Full model without Association",
        y.unit, y.range)

# Add everything except coherence 
m$InterceptAssocPrecrit1Interaction <- m$`Coef_(Intercept)` + m$Association*m$Coef_Association + m$Coherence*0 + m$logRT_precrit1*m$Coef_logRT_precrit1 + m$Association*m$Coherence*m$`Coef_Association:Coherence`
p2 <- plotSPR(m, "InterceptAssocPrecrit1Interaction", "Estimates: Full model without Coherence",
        y.unit, y.range)

# Add everything except precritical 1 
m$InterceptAssocCoherenceInteraction <- m$`Coef_(Intercept)` + m$Association*m$Coef_Association + m$Coherence*m$Coef_Coherence + m$logRT_precrit1*0 + m$Association*m$Coherence*m$`Coef_Association:Coherence`
p3 <- plotSPR(m, "InterceptAssocCoherenceInteraction", "Estimates: Full model without Precrit1",
        y.unit, y.range)


# Add everything except the interaction term 
m$InterceptAssocCoherencePrecrit1 <- m$`Coef_(Intercept)` + m$Association*m$Coef_Association + m$Coherence*m$Coef_Coherence + m$logRT_precrit1*m$Coef_logRT_precrit1 + m$Association*m$Coherence*0
p4 <- plotSPR(m, "InterceptAssocCoherencePrecrit1", "Estimates: Full model without the interaction term",
        y.unit, y.range)

# Sanity check: full model 
m$Full <- m$`Coef_(Intercept)` + m$Association*m$Coef_Association  + m$Coherence*m$Coef_Coherence + m$logRT_precrit1*m$Coef_logRT_precrit1 +  m$Association*m$Coherence*m$`Coef_Association:Coherence`
p5 <- plotSPR(m, "Full", "Estimates: Full model", y.unit, y.range)

# Observed data 
p.observed <- plotSPR(m, DV, "Observed RTs", y.unit, y.range)

grid.arrange(p1, p2, p3, 
             p4, p5, p.observed,
             nrow=2,
             top = textGrob("Setting individual predictors to zero", gp=gpar(fontsize=14, fontface=2)))
```
