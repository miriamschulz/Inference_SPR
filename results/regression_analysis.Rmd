---
title: "SPR results: regression-based analysis of the reading times"
author: "Miriam Schulz"
date: "10/11/2022"
output:
  html_document:
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      collapse = TRUE,
                      fig.height = 6, fig.width = 9)
```


# About

This script contains an rRT analysis of the inference reading time data (SPR1) based on the rERP approach in Brouwer, Delogu & Crocker (2020). 


# Read data and preprocess

In this section:

- read in the data
- remove outliers based on SPR (word-by-word) RTs and context sentence RTs
- remove incorrectly answered trials
- add log-transformed RTs
- scale the predictors

```{r include = FALSE}
# Workspace and libraries
rm(list = ls())
library(tidyverse)
library(lme4)              # for lmer()
library(lmerTest)          # for summary(lmer.model)
library(broom)             # for tidy(modeloutput)
library(gridExtra)         # for grid.arrange()
library(grid)              # for textGrob()
library(RColorBrewer)      # for color palettes
library(pander)            # for pander(df)
source("functions.R")      # custom preprocessing and helper functions
source("functions_rRT.R")  # rRT functions
```

Read in data and remove fillers, practice and non-critical regions:

```{r message=FALSE}
# Read data
df <- read.csv("results_reads.csv", header = TRUE)

# Exclude filler and practice trials
df <- removeFillersPractice(df)

# Exclude non-critical regions
df <- removeRegions(df, keep.regions=-1:2)
```

Next, the raw data are visualized with histograms and QQ plots before removing outliers.

Histograms and residual plots:

```{r echo=FALSE, fig.width=10, fig.height=10}
par(mfrow=c(2,2))
# Histograms

# Histogram of RTs:
hist(df$RT,
     breaks = 50,
     col='steelblue',
     main='Untransformed RTs')

# Histogram of log RTs :
hist(log(df$RT),
     breaks = 50,
     col='steelblue',
     main='Log-transformed RTs')

# QQ plots

# Untransformed RTs
qqnorm(df$RT,
       col='steelblue',
       pch=16,
       main='QQ plot of untransformed RTs')

# Log-transformed RTs
qqnorm(log(df$RT),
       col='steelblue',
       pch=16,
       main='QQ plot of log-transformed RTs')
# Save plot
#ggsave("./plots/RT_hist_QQ.pdf", plot = last_plot(),
#       width = 10, height = 10, dpi = 300)
par(mfrow=c(1,1))  # reset
```

## Remove SPR outliers

```{r message=FALSE}
# Optional: remove items with low accuracy in B
#df <- filter(df, ! Item %in% c(5,13,25))

# Remove outliers: SPR (word RTs) - SD
df <- removeOutliersSPR(df,
                         method="sd",
                         sd.value=4,
                         entire.trial = TRUE,
                         regions = -1:2)

# Remove outliers: SPR (word RTs) - threshold values
#df <- removeOutliersSPR(df,
#                        method="threshold",
#                        min.rt=100,
#                        max.rt=1000,
#                        entire.trial = TRUE,
#                        regions = -1:2)
```

Histograms and residual plots *after* removing SPR outliers:

```{r echo=FALSE, fig.width=10, fig.height=10}
par(mfrow=c(2,2))
# Histograms

# Histogram of RTs:
hist(df$RT,
     breaks = 50,
     col='steelblue',
     main='Untransformed RTs')

# Histogram of log RTs :
hist(log(df$RT),
     breaks = 50,
     col='steelblue',
     main='Log-transformed RTs')

# QQ plots

# Untransformed RTs
qqnorm(df$RT,
       col='steelblue',
       pch=16,
       main='QQ plot of untransformed RTs')

# Log-transformed RTs
qqnorm(log(df$RT),
       col='steelblue',
       pch=16,
       main='QQ plot of log-transformed RTs')
# Save plot
#ggsave("./plots/RT_hist_QQ.pdf", plot = last_plot(),
#       width = 10, height = 10, dpi = 300)
par(mfrow=c(1,1))  # reset
```

Box-Cox plot:

```{r echo=FALSE, fig.width=4, fig.height=4}
# Boxcox plot
MASS::boxcox(df$RT ~ df$Cond)
```

Normality test (Shapiro-Wilk):

```{r}
# Untransformed RTs:
shapiro.test(filter(df, Region >= 0)$RT)

# Log-transformed RTs:
shapiro.test(log(filter(df, Region >= 0)$RT))
```

## Remove context sentence RT outliers and incorrectly answered trials

```{r fig.width=10, fig.height=5}
# Remove outliers: context sentence reading times
df <- removeOutliersContext(df, min.rt=500, max.rt=30000)

# Remove trials with incorrect plausibility ratings
df <- removeIncorrect(df)

# Visualize context sentence reading times with a histogram:
par(mfrow=(c(1,2)))
hist(
    filter(df, Region == 0)$ContextRT,
    breaks = 50,
    #xlim = c(0, 1000),
    ##ylim = c(0, 800),
    xlab = "Untransformed Context Sentence RT (ms)",
    col = "steelblue",
    main = NULL
)

hist(
    log(filter(df, Region == 0)$ContextRT),
    breaks = 50,
    #xlim = c(0, 1000),
    ##ylim = c(0, 800),
    xlab = "Log-transformed Context Sentence RT (ms)",
    col = "steelblue",
    main = NULL
)
par(mfrow=(c(1,1))) # reset
```

```{r echo=FALSE, fig.width=4, fig.height=3.5}
# Visualize average context reading times by condition:
cond.means.contextRTs <- aggregMeans(df, as.formula(ContextRT ~ Cond))
round(cond.means.contextRTs$Mean)
round(cond.means.contextRTs$SD)

# Boxplot:
p <-
  #df %>% 
  #filter(Region==0) %>% 
  #ggplot(aes(x = Cond, y = ContextRT, fill=Cond)) + 
  #geom_boxplot() + 
  cond.means.contextRTs %>% 
  ggplot(aes(x = Cond, y = Mean, fill=Cond)) + 
  geom_bar(stat='identity', width=0.8) + 
  geom_errorbar(
    aes(ymin = Mean - SE, ymax = Mean + SE),
    width = 0.15,
    linewidth = 0.3
  ) +
  xlab("Condition") +
  ylab("RT (ms)") +
  scale_fill_manual(values = c("cornflowerblue", "chartreuse3",
                                "tomato2", "darkgoldenrod1")) +
  theme_minimal() +
  theme(legend.position="None",
        text = element_text(size = 13))
filename <- paste0("./plots/", "context_RT.pdf")
ggsave(filename, plot = p, width = 3, height = 3)
p + ggtitle("Context sentence RT by condition")
```

## Further preprocessing: transformations etc.

In this subsection: 

- Rename variables
- Transform to factor when necessary
- Combine Inference+Coherence ratings into a new combined predictor with PCA, extracting the first component
- add precritical reading times as predictors 
- add log-transformed versions of the reading times (the SPR RT (DV) as well as predictors (IVs))
- standardize the predictors

```{r message=FALSE}
# Rename variables 
rating_colnames <- str_remove(names(df), "Rating")
names(df) <- rating_colnames
df <- rename(df, ProdNorms = ProductionPercentage)

# Transform variables to factors
df$Cond <- as.factor(df$Cond)
df$Item <- as.factor(as.numeric(as.character(df$Item)))
df$Subject <- as.factor(as.numeric(as.character(df$Subject)))

# Transform the binary plausibility predictor to numeric, then to factor
df$Plausible <- as.factor(ifelse(df$Plausible == "Yes", 1, 0))

# Better: combine the predictors using PCA
pca_fit <- stats::prcomp(dplyr::select(df, Inference, Coherence), scale=TRUE)
df$InfCoPC1 <- pca_fit$x[,1]

# Invert predictor scales 
#df$AssociationRating <- df$AssociationRating - 7
#df$CoherenceRating <- df$CoherenceRating - 7
#df$InferenceRating <- df$InferenceRating - 7

# Extract precritical RT -1 and add to df:
df.precrit1 <- filter(df, Region == -1) %>% 
  dplyr::select(Item, Cond, Subject, RT) %>% 
  rename(RT_precrit1 = RT)
df <- merge(df, df.precrit1, by = c("Item", "Cond", "Subject"))

# Extract precritical RT -2 and add to df:
#df.precrit2 <- filter(df, Region == -2) %>% 
#  dplyr::select(Item, Cond, Subject, RT) %>% 
#  rename(RT_precrit2 = RT)
#df <- merge(df, df.precrit2, by = c("Item", "Cond", "Subject"))

# Add log-transformed RTs
df$logRT <- log(df$RT)
df$logRT_precrit1 <- log(df$RT_precrit1)
#df$logRT_precrit2 <- log(df$RT_precrit2)

# Order df by Region
df <- arrange(df, Region)

# Scale predictors (careful: needs to be performed AFTER removing data)
df <- scalePredictors(
  df,
  c(
    "ProdNorms",
    "Association",
    "Inference",
    "Coherence",
    "InfCoPC1",
    "RT_precrit1",
    #"RT_precrit2",
    "logRT_precrit1"
    #"logRT_precrit2"
  )
)

str(df)
```


# Observed RTs

## Mean RTs by condition for each region of interest

```{r}
# Summary:
# Untransformed RTs
pander::pander(x <- df %>%
                 group_by(Cond, Region) %>%
                 summarize(Mean = mean(RT)) %>%
                 spread(Region, Mean) %>%
  mutate_if(is.numeric, round))
# Log-transformed RTs
pander::pander(x <- df %>%
                 group_by(Cond, Region) %>%
                 summarize(Mean = mean(logRT)) %>%
                 spread(Region, Mean))
# With SD and SE:
pander::pander(aggregMeans(df,
                  as.formula(RT ~ Region + Cond),
                  round.data = TRUE) %>%
        mutate_if(is.numeric, round))
```

## Plots

### RTs by region and condition 

```{r fig.width=6.5, fig.height=4.5}
#df <- filter(df, !Item %in% c(5, 13, 25))
p1 <- plotSPR(df, "RT", "RT", c(260, 325))
p2 <- plotSPR(df, "logRT", "logRT", c(5.52,5.73))
ggsave("./plots/observed_RTs.pdf", p2,
       width = 3.2, height = 3.5, dpi=300)
grid.arrange(p1+ggtitle("Untransformed RTs"),
             p2+ggtitle("Log-transformed RTs"),
             ncol=2,
             top = textGrob("Observed reading times",
                            gp=gpar(fontsize=14, fontface=2)))
```


### Density plot: variation across regions 

Check the *range* of the reading times in the critical regions (i.e. the spread of the variation).

Larger ranges implies that the residuals will be larger due to the increased amount of gvariation in that region.

```{r warning = FALSE, fig.width=6, fig.height=4}
spread.color.palette <- c("-1" = "rosybrown1",
                          "0" = "black",
                          "1" = "deeppink2", 
                          "2" = "purple3")
# Density plot
p.spread <- df %>%
  filter(Region %in% -1:2) %>%
  ggplot(aes(
    x = logRT,
    group = Region,
    linetype = factor(Region),
    color = factor(Region)
  )) +
  geom_density(adjust = 0.8,
               linewidth = 1,
               key_glyph = draw_key_smooth) +
  #xlim(c(0, 1000)) +
  ylab("Density") +
  scale_color_manual("Region",  # Legend title
                     values = spread.color.palette,
                     labels = c("Pre-critical", "Critical",
                                "Spillover", "Post-spillover")) +
  scale_linetype_manual(
    "Region",  # Legend title
    values = c("dotdash", "solid", "dashed", "dotted"),
    labels = c("Pre-critical", "Critical",
               "Spillover", "Post-spillover")
  ) +
  theme_minimal()

ggsave("./plots/spread_RT.pdf", p.spread,
       width = 5, height = 3.5, dpi=300)

p.spread + ggtitle("Spread of RTs by Region")
```

### Task effect: decreasing RTs

Check the presence of a task effect (decreasing RTs over the course of the experiment) by subject.

The precritical region RTs are used here since target words differ in length from trial to trial, while the precritical word is always a determiner.

**Method 1: RT ~ Block**

Aggregate mean RT ~ Block:

```{r fig.width=4, fig.height=3}
mean.RT.block <- aggregMeans(filter(df, Region==-1),
                             as.formula(RT ~ Block))

p.taskeffect <- mean.RT.block %>%
  ggplot(aes(x = Block, y = Mean, color = Block)) +
  geom_point(size = 5,
             shape = "cross") +
  geom_errorbar(aes(ymin = Mean - SE,
                    ymax = Mean + SE),
                width = 0.2,
                linewidth = 0.3) +
  xlab("Time (Block)") +
  ylab("Mean RT (ms)") +
  scale_colour_brewer(palette="Dark2")+
  theme_minimal()

ggsave("./plots/taskeffect.pdf", p.taskeffect,
       width = 4, height = 3, dpi=300)

p.taskeffect + ggtitle("Mean RT trial number")

```


**Method 2: RT ~ TrialNumber**

```{r fig.width=7, fig.height=4}
mean.RT.trialnum <- df %>% 
  filter(Region == -1) %>% 
  group_by(TrialNum) %>% 
  summarize(MeanRT = mean(RT)) %>% 
  data.frame()

mean.RT.trialnum %>% 
  ggplot(aes(x=TrialNum, y=MeanRT)) + 
  geom_smooth(method = 'lm', se=TRUE, alpha = .2, color='steelblue') + 
  geom_line(color='steelblue') + 
  #ylim(c(0,350)) + 
  theme_minimal() +
  ggtitle("Mean RT trial number")

df %>%
  filter(Region == -1) %>% 
  ggplot(aes(x = TrialNum, y = RT, color=Subject, group=Subject)) + 
  #geom_point(size=1.5, shape="cross", alpha = 0.5) + 
  geom_smooth(method = 'lm', size = 0.5, se=TRUE, alpha = .2, aes(fill=Subject)) +
  #geom_smooth(method = 'lm', se=TRUE, alpha = .2, aes(x = TrialNum, y = RT)) +
  ggtitle("RT by Subject + trial number") +
  theme_minimal() +
  theme(legend.position = "None")
```

## Traditional analysis

```{r}
precrit <- filter(df, Region==-1)
crit <- filter(df, Region==0)
spill1 <- filter(df, Region==1)
spill2 <- filter(df, Region==2)

summary(lm(logRT ~ 1 + Cond, data=precrit))
summary(lm(logRT ~ 1 + Cond, data=crit))
summary(lm(logRT ~ 1 + Cond, data=spill1))
summary(lm(logRT ~ 1 + Cond, data=spill2))

summary(lmer(logRT ~ Association + InfCoPC1 + (1|Subject) + (1|Item), data=precrit))
summary(lmer(logRT ~ Association + InfCoPC1 + (1|Subject) + (1|Item), data=crit))
summary(lmer(logRT ~ Association + InfCoPC1 + (1|Subject) + (1|Item), data=spill1))
summary(lmer(logRT ~ Association + InfCoPC1 + (1|Subject) + (1|Item), data=spill2))

summary(lmer(logRT ~ Association + Inference + (1|Subject) + (1|Item), data=precrit))
summary(lmer(logRT ~ Association + Inference + (1|Subject) + (1|Item), data=crit))
summary(lmer(logRT ~ Association + Inference + (1|Subject) + (1|Item), data=spill1))
summary(lmer(logRT ~ Association + Inference + (1|Subject) + (1|Item), data=spill2))

summary(lmer(logRT ~ Association + Coherence + (1|Subject) + (1|Item), data=precrit))
summary(lmer(logRT ~ Association + Coherence + (1|Subject) + (1|Item), data=crit))
summary(lmer(logRT ~ Association + Coherence + (1|Subject) + (1|Item), data=spill1))
summary(lmer(logRT ~ Association + Coherence + (1|Subject) + (1|Item), data=spill2))

summary(lmer(logRT ~ Association + Inference + logRT_precrit1 + (1|Subject) + (1|Item), data=crit))
summary(lmer(logRT ~ Association + Inference + logRT_precrit1 + (1|Subject) + (1|Item), data=spill1))
summary(lmer(logRT ~ Association + Inference + logRT_precrit1 + (1|Subject) + (1|Item), data=spill2))
```


# Models 


## Define model parameters

Define general model parameters:

- regions to model
- whether to use raw or log-transformed RTs
- which kind of model to run:
  - "lm": simple LM
  - "lm.by.subj": by-subject LMs
  - "lmer": LMER

```{r}
regions <- -1:2
log.RTs <- TRUE
m.type = "lm.by.subj"

if (log.RTs == TRUE) {
  DV <- "logRT"
  precrit1 <- "logRT_precrit1"
  precrit2 <- "logRT_precrit2"
  y.unit <- "Log RT"
  y.range <- c(5.55, 5.75)
  y.range.res <- c(-0.07, 0.07)
} else {
  DV <- "RT"
  precrit1 <- "RT_precrit1"
  precrit2 <- "RT_precrit2"
  y.unit <- "Raw RT (ms)"
  y.range <- c(260, 320)
  y.range.res <- c(-20, 20)
}
```


## Intercept (baseline) LM model

Following the logic of Brouwer et al. (2020), the analysis starts with a baseline model of the variance in the signal. 
The baseline model assumes that no factors were manipulated and that all trials belong to the same condition. 
Therefore, the resulting estimate for each trial in a given region will simply be the average over all trials (and conditions; equivalent to an intercept-only model) in that region. 

Unlike in rERP modeling, different models do not need to be fitted for different electrodes, but like in rERP modeling, different models will be fitted for each subject ($N=40$) and time point (i.e., region, $N=4$: pre-critical region, critical region, post-critical region 1, post-critical region 2), yielding a total of $40 * 4 = 160$ models.

However, here we first start with an even simpler baseline model averaging over subjects.

```{r, results = FALSE, echo = FALSE, fig.width=9, fig.height=5}
# Model formula
m.formula <- as.formula(paste0(DV, " ~ 1"))

# Run model(s) and generate plots
modelAndPlot("Intercept",
             m.formula,
             df,
             m.type,
             regions,
             DV,
             y.unit,
             y.range,
             y.range.res,
             coef.plot = FALSE)

#TODO: 
# - remove top title for saved plot
# - make legend larger but keep only 1 legend per grid.arrange
# - begin from building the full model and then eliminate predictors
knitr::knit_exit()
```



## Models with a single predictor 

### Intercept + binary Plausibility LM

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Plausible"))
modelAndPlot("Intercept+Plausibility",
             m.formula,
             df,
             m.type,
             regions,
             DV, 
             y.unit, 
             y.range, 
             y.range.res)
```


### Intercept + Association LM

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Association"))
modelAndPlot(
  "Intercept+Association",
  m.formula,
  df,
  m.type,
  regions,
  DV,
  y.unit,
  y.range,
  y.range.res
)
```


### Intercept + Coherence LM

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Coherence"))
modelAndPlot(
  "Intercept+Coherence",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)
```


### Intercept + Inference LM

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Inference"))
modelAndPlot(
  "Intercept+Inference",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)
```


### Intercept + PrecritRT 1 LM

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + ", paste0(precrit1)))
modelAndPlot(
  "Intercept+PrecritRT1",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)
```


### Intercept + PrecritRT 2 LM

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + ", precrit2))
modelAndPlot(
  "Intercept+PrecritRT2",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)
```



## Models with more than 1 predictor

### Intercept + Association + Coherence 

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Association + Coherence"))
modelAndPlot(
  "Intercept+Association+Coherence",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)
```


### Intercept + Association + Coherence + Precrit_RT1

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Association + Coherence + ", precrit1))
modelAndPlot(
  "Intercept+Association+Coherence+Precrit1",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)
```


### Intercept + Association + Inference + Precrit_RT1

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Association + Inference + ", precrit1))
modelAndPlot(
  "Intercept+Association+Inference+Precrit1",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)
```


### Intercept + Association + Coherence + Precrit_RT2

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Association + Coherence + ", precrit2))
modelAndPlot(
  "Intercept+Association+Coherence+Precrit2",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)
```


### Intercept + Association + Coherence + Precrit_RT1 + Precrit_RT2 + Plausible

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV,
                               " ~ 1 + Association + Coherence + Plausible + ",
                               precrit1, " + ", precrit2))
modelAndPlot(
  "Intercept+Association+Coherence+Precrit1&2+Plausibility",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)
```



## Models with interaction terms

### Association * Coherence

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ Association * Coherence "))
modelAndPlot(
  "Association*Coherence",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)
```

### Association * Coherence * precrit1

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ Association * Coherence * ", precrit1))
modelAndPlot(
  "Association*Coherence*Precrit1",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)
```

### Association * Coherence * precrit2

```{r, results = FALSE, fig.height = 6, fig.width = 9}
m.formula <- as.formula(paste0(DV, " ~ Association * Coherence * ", precrit2))
modelAndPlot(
  "Association*Coherence*Precrit2",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)
```

### Intercept + Association * Coherence * precrit1 * precrit2

```{r, results = FALSE, fig.height = 6, fig.width = 9}
m.formula <- as.formula(paste0(DV, " ~ Association * Coherence * ",
                               precrit1, " * ", precrit2))
modelAndPlot(
  "Association*Coherence*Precrit1*Precrit2",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res,
  coef.plot = FALSE  # since too many coefficients 
)
```


### Intercept + Association + Coherence + Association : Coherence + RT_Precrit1

```{r, results = FALSE}
m.formula <- as.formula(paste0(
  DV,
  " ~ Association + Coherence + Association:Coherence + ",
  precrit1
))

modelAndPlot(
  "Intercept+Association+Coherence+Association:Coherence+Precrit1",
  m.formula,
  df, m.type, regions, DV,
  y.unit, y.range, y.range.res
)


model.output <- runModels(df, m.type, m.formula, regions = regions)
p <- plotSPR(model.output, DV, "Observed RTs", y.unit, y.range)
filename <- paste0("./plots/", DV, "_", "Observed_only", ".png")
ggsave(filename, plot = p, width = 5, height = 4)
```


## lmer 


### Intercept + Coherence, Random Intercepts 

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Coherence +
                              (1 | Item) + (1 | Subject)"))
modelAndPlot(
  "Intercept+Coherence",
  m.formula,
  df, "lmer", regions, DV,
  y.unit, y.range, y.range.res
)
```

### Intercept + Association + Coherence, Random Intercepts 

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Association + Coherence +
                              (1 | Item) + (1 | Subject)"))
modelAndPlot(
  "Intercept+Association+Coherence",
  m.formula,
  df, "lmer", regions, DV,
  y.unit, y.range, y.range.res
)
```


### Intercept + Association + Coherence + Precrit1, Random Intercepts 

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Association + Coherence + ",
                               precrit1,
                              " + (1 | Item) + (1 | Subject)"))
modelAndPlot(
  "Intercept+Association+Coherence+Precrit1",
  m.formula,
  df, "lmer", regions, DV,
  y.unit, y.range, y.range.res
)
```


### Intercept + Association + Coherence + Precrit1 + Association:Coherence, Random Intercepts 

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Association + Coherence + Association:Coherence + ",
                               precrit1,
                              " + (1 | Item) + (1 | Subject)"))
modelAndPlot(
  "Intercept+Association+Coherence+Association:Coherence+Precrit1",
  m.formula,
  df, "lmer", regions, DV,
  y.unit, y.range, y.range.res
)
```

### Intercept + Association*Coherence*Precrit1, Random Intercepts 

```{r, results = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Association* Coherence * ",
                               precrit1,
                              " + (1 | Item) + (1 | Subject)"))
modelAndPlot(
  "Association*Coherence*Precrit1",
  m.formula,
  df, "lmer", regions, DV,
  y.unit, y.range, y.range.res
)
```



## Setting predictors to zero

```{r}
m.formula <- as.formula(paste0(DV, " ~ 1 + Association + Coherence +",
                               precrit1))

m.formula <- as.formula(paste0(
  DV,
  " ~ Association + Coherence + Association:Coherence + ",
  precrit1
))

m <- runModels(df,
               "lm.by.subj",
               m.formula,
               regions)

# Set predictors to zero

#TODO: do this on the full model (here, only performed on the model without an interaction term)

# Plot only the intercept
m$InterceptOnly <- m$`Coef_(Intercept)`
plotSPR(m, "InterceptOnly", "Estimates: Intercept only", y.unit, y.range)

# Add association only
m$InterceptAssoc <- m$`Coef_(Intercept)` + m$Association*m$Coef_Association 
plotSPR(m, "InterceptAssoc", "Estimates: Intercept+Assoc", y.unit, y.range)

# Add coherence only
m$InterceptCoherence <- m$`Coef_(Intercept)` + m$Coherence*m$Coef_Coherence
plotSPR(m, "InterceptCoherence", "Estimates: Intercept+Coherence", y.unit, y.range)

# Add precritical only 
m$InterceptPrecrit1 <- m$`Coef_(Intercept)` + m$logRT_precrit1*m$Coef_logRT_precrit1
plotSPR(m, "InterceptPrecrit1", "Estimates: Intercept+Precrit1", y.unit, y.range)

# Add everything except association 
m$InterceptCoherencePrecrit1 <- m$`Coef_(Intercept)` + m$Association*0  + m$Coherence*m$Coef_Coherence + m$logRT_precrit1*m$Coef_logRT_precrit1
plotSPR(m, "InterceptCoherencePrecrit1", "Estimates: Intercept+Coherence+Precrit1", y.unit, y.range)

# Add everything except coherence 
m$InterceptAssocPrecrit1 <- m$`Coef_(Intercept)` + m$Association*m$Coef_Association  + m$Coherence*0 + m$logRT_precrit1*m$Coef_logRT_precrit1
plotSPR(m, "InterceptAssocPrecrit1", "Estimates: Intercept+Association+Precrit1", y.unit, y.range)

# Sanity check: full model 
m$Full <- m$`Coef_(Intercept)` + m$Association*m$Coef_Association  + m$Coherence*m$Coef_Coherence + m$logRT_precrit1*m$Coef_logRT_precrit1 +  m$Association*m$Coherence*m$`Coef_Association:Coherence`
plotSPR(m, "Full", "Estimates: Full model", y.unit, y.range)
```


## Models with ProductionNorms as predictor

### Intercept + ProdNorms

```{r, results = FALSE}
# Model formula
m.formula <- as.formula(paste0(DV, " ~ 1 + Association + Coherence + ", precrit2))

# Run a model for each region
m.intercept.assoc.coherence.precrit2 <- runModels(df, m.type, m.formula, regions = regions)

# Generate plots
p <- generatePlots(m.intercept.assoc.coherence.precrit2,
                   "Intercept+Association+Coherence+Precrit2", m.type, DV,
                   y.unit, y.range, y.range.res)
```




```{r, results = FALSE, eval = FALSE}
m.formula <- as.formula(paste0(DV, " ~ 1 + Coherence + (1 + Coherence | Item) +
                               (1 + Coherence | Subject)"))


m.lmer <- lmer(RT ~ 1 + Association + Coherence + (1 + Coherence| Subject) + (1 +Coherence | Item),
           data = filter(df, Region == 0))
summary(m.lmer)


#TODO add interaction term 
#TODO: set individual predictors to zero from full model and inspect/plot (plot estimate vs. residual)
#TODO: check if lmer fixed eff coefs are comparable to lm fixed eff coefs 
#TODO loop over subjects, individual model per subject, then average 


# Model output 
fixef(m.lmer)  # fixed effects 
summary(m.lmer)$coefficients
coef(m.lmer)   # subject/item estimates
ranef(m.lmer)  # deviation of subject/item from main effect

# Subject estimates with coef() are equal to main effect + ranef():
est <- ranef(m.lmer)$Subject
cf <- coef(m.lmer)$Subject
est$"(Intercept)" + fixef(m.lmer)[[1]] == cf$"(Intercept)"


  
subj.coef <- coef(m.lmer)$Subject
item.coef <- coef(m.lmer)$Item
subj.ranef <- ranef(m.lmer)$Subject
item.ranef <- ranef(m.lmer)$Item

mean(subj.coef$Coherence)
mean(item.coef$Coherence)
range(subj.coef$Coherence)
range(item.coef$Coherence)
round(mean(subj.ranef$Coherence), 5)
round(mean(item.ranef$Coherence), 5)

mean(subj.coef[, 1])
mean(item.coef[, 1])
range(subj.coef[, 1])
range(item.coef[, 1])
round(mean(subj.ranef[, 1]), 5)
round(mean(item.ranef[, 1]), 5)

coef(summary(m.lmer))
```


Improved version: 

```{r, fig.height = 7, fig.width = 14}
m.formula <- as.formula(paste0(
  DV,
  " ~ Association + Coherence + Association:Coherence + ",
  precrit1
))

m <- runModels(df,
               "lm.by.subj",
               m.formula,
               regions)

# Set predictors to zero: start with all zero except the intercept,
# then add in more predictors

# Plot only the intercept
m$InterceptOnly <- m$`Coef_(Intercept)`
plotSPR(m, "InterceptOnly", "Estimates: Intercept only", y.unit, y.range)

# Add association only
m$InterceptAssoc <- m$`Coef_(Intercept)` + m$Association*m$Coef_Association 
plotSPR(m, "InterceptAssoc", "Estimates: Intercept+Assoc", y.unit, y.range)

# Add coherence only
m$InterceptCoherence <- m$`Coef_(Intercept)` + m$Coherence*m$Coef_Coherence
plotSPR(m, "InterceptCoherence", "Estimates: Intercept+Coherence", y.unit, y.range)

# Add precritical only 
m$InterceptPrecrit1 <- m$`Coef_(Intercept)` + m$logRT_precrit1*m$Coef_logRT_precrit1
plotSPR(m, "InterceptPrecrit1", "Estimates: Intercept+Precrit1", y.unit, y.range)

# Add everything except association 
m$InterceptCoherencePrecrit1Interaction <- m$`Coef_(Intercept)` + m$Association*0 + m$Coherence*m$Coef_Coherence + m$logRT_precrit1*m$Coef_logRT_precrit1 + m$Association*m$Coherence*m$`Coef_Association:Coherence`
p1 <- plotSPR(m, "InterceptCoherencePrecrit1Interaction", "Estimates: Full model without Association",
        y.unit, y.range)

# Add everything except coherence 
m$InterceptAssocPrecrit1Interaction <- m$`Coef_(Intercept)` + m$Association*m$Coef_Association + m$Coherence*0 + m$logRT_precrit1*m$Coef_logRT_precrit1 + m$Association*m$Coherence*m$`Coef_Association:Coherence`
p2 <- plotSPR(m, "InterceptAssocPrecrit1Interaction", "Estimates: Full model without Coherence",
        y.unit, y.range)

# Add everything except precritical 1 
m$InterceptAssocCoherenceInteraction <- m$`Coef_(Intercept)` + m$Association*m$Coef_Association + m$Coherence*m$Coef_Coherence + m$logRT_precrit1*0 + m$Association*m$Coherence*m$`Coef_Association:Coherence`
p3 <- plotSPR(m, "InterceptAssocCoherenceInteraction", "Estimates: Full model without Precrit1",
        y.unit, y.range)


# Add everything except the interaction term 
m$InterceptAssocCoherencePrecrit1 <- m$`Coef_(Intercept)` + m$Association*m$Coef_Association + m$Coherence*m$Coef_Coherence + m$logRT_precrit1*m$Coef_logRT_precrit1 + m$Association*m$Coherence*0
p4 <- plotSPR(m, "InterceptAssocCoherencePrecrit1", "Estimates: Full model without the interaction term",
        y.unit, y.range)

# Sanity check: full model 
m$Full <- m$`Coef_(Intercept)` + m$Association*m$Coef_Association  + m$Coherence*m$Coef_Coherence + m$logRT_precrit1*m$Coef_logRT_precrit1 +  m$Association*m$Coherence*m$`Coef_Association:Coherence`
p5 <- plotSPR(m, "Full", "Estimates: Full model", y.unit, y.range)

# Observed data 
p.observed <- plotSPR(m, DV, "Observed RTs", y.unit, y.range)

grid.arrange(p1, p2, p3, 
             p4, p5, p.observed,
             nrow=2,
             top = textGrob("Setting individual predictors to zero", gp=gpar(fontsize=14, fontface=2)))
```
