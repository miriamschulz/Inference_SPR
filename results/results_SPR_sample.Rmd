---
title: "Inference SPR results: sampling"
author: "Miriam Schulz"
date: "9/15/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## About

This script randomly samples a subset of participants from the results to get an idea of the variation in the data.


## Preliminaries

```{r, include = FALSE}
# Workspace, libraries and functions
rm(list = ls())  # clear workspace (optional)
library(tidyverse)
library(grid)
library(gridExtra)
library(sciplot)  # for se function
source("results_SPR_functions.R") # custom functions 
```

Read in and preprocess data:

```{r, results = FALSE}
# Read in preprocessed results file:
reads <- read.csv("results_reads.csv", header = TRUE)

# Keep only regions of interest
reads <- droplevels(filter(reads, Region %in% -1:2))

# Remove fillers and practice trials
reads <- droplevels(filter(reads, Item < 100))

# Remove subject(s)
#reads <- filter(reads, Subject != 6)

# Add log RTs
reads$logRT <- log(reads$RT)

# Convert variables to numeric / factor:
reads[ ,c("Subject", "IPhash", "Cond", "Block", "Order", "Plausible", 
          "Region", "PlausibilityRating")] <-
  lapply(reads[ ,c("Subject", "IPhash", "Cond", "Block", "Order", "Plausible", 
                   "Region", "PlausibilityRating")], as.factor)

# Inspect:
str(reads)
```

Exclude data. Criteria:

- outlier RTs
- incorrect plausibility ratings
- context reading times < 300ms

```{r}
# Check the original range of the RTs
range(reads$RT)

# Define thresholds for data exclusion
min.threshold <- 80
max.threshold <- 1500

# Check the number of data points concerned by small RTs:
nrow(filter(reads, RT <= min.threshold))
# Check the number of data points concerned by large RTs:
nrow(filter(reads, RT >= max.threshold))

# Data completeness check (for target region)
xtabs(~ Cond + Subject + Region, filter(reads, Region %in% -1:2))

# Filter RTs to lie within chosen range
reads <- filterRTs(reads, 
                   c(min.threshold, max.threshold),
                   method = "thresholds", 
                   remove.incorrect = TRUE, 
                   remove.contexts = 300)

# Data completeness check (for target region):
# minimum and maximum number of datapoints per subject/condition
min(xtabs(~ Cond + Subject + Region, data = reads))
max(xtabs(~ Cond + Subject + Region, data = reads))

# Check that RTs are in the specified range 
range(reads$RT)
```

Define a plotting function:

```{r}
# Define a line plot function
line.plot <- function(df) {
  if (log.RTs == TRUE) {
    y.axis.range <- c(5.5, 5.85)
  } else {
    y.axis.range <- c(225, 360)
  }
  p <- df %>%
    ggplot(aes(x = Region, y = MeanRT, color=Cond, group=Cond)) + 
      geom_point(size=2.5, shape="cross") + 
      geom_line(size=0.5) +
      geom_errorbar(aes(ymin = MeanRT - SE, ymax = MeanRT + SE),
                    width=0.1, size=0.3) +
      geom_vline(xintercept=0, linetype="dashed") +
      #geom_smooth(method = 'lm', se=TRUE, alpha = .2, aes(fill=Cond)) +
      scale_color_manual("Condition",  # Legend title
                         values=c("cornflowerblue", "chartreuse3",
                                  "tomato2", "darkgoldenrod1")) +
      ylim(y.axis.range) +
      theme_minimal()
  p
}
```


## Sampling

Sample an equal number of participants per list (with replacement across, but not within, individual samples).

```{r fig.height = 10, fig.width = 15}
# Set random seed (try different values)
seed <- 42
set.seed(seed)

# Set parameters and initialize
Nsamples.per.list <- 3
Niterations <- 9
means.cond.list <- list()
plot.list <- list()
log.RTs = TRUE  # if TRUE, use log RTs, else raw RTs

# Sample
for (i in 1:Niterations) {
  
  # Randomly sample from each list.
  # Subjects 1-5 are list 1, order1; subjects 21-25 are list 1, order 2, etc.
  participants.sample <- c(sample(c(1:5, 21:25), Nsamples.per.list),
                           sample(c(6:10, 26:30), Nsamples.per.list),
                           sample(c(11:15, 31:35), Nsamples.per.list),
                           sample(c(16:20, 36:40), Nsamples.per.list))
  reads.sample <- filter(reads, Subject %in% participants.sample)
  
  # Aggregate sampled data 
  if (log.RTs == TRUE) {
    means.cond.sample <-
      aggMeansSE(reads.sample, c("logRT", "Cond", "Region"))
    colnames(means.cond.sample) <- c("Cond", "Region", "MeanRT", "SE")
  } else {
    means.cond.sample <-
      aggMeansSE(reads.sample, c("RT", "Cond", "Region"))
  }
  means.cond.sample$Iteration <- i  # annotate iteration
  means.cond.list[[i]] <- as.data.frame(means.cond.sample)
  
  # Generate and store plot for current sample 
  p.sample <- line.plot(means.cond.sample)
  plot.list[[i]] <- p.sample
}

# Save or print plots
filename <- paste0("./plots/sample_",
                   Nsamples.per.list*4,
                   "subj_", Niterations,
                   "reps_seed", seed, "_balanced_lists", 
                   ifelse(log.RTs == TRUE, "_log", ""),
                   ".png")
#png(file=filename, width = 1200, height = 800)  # good size for 12 samples
png(file=filename, width = 900, height = 600)   # good size for 9 samples
p <- grid.arrange(grobs = plot.list, nrow = 3,
             top = textGrob(paste0("Mean ", 
                                   ifelse(log.RTs == TRUE, "log ", ""),
                                   " RTs for subsets of ",
                                   Nsamples.per.list*4,
                                   " randomly sampled subjects (",
                                   Nsamples.per.list, 
                                   " per list)"),
                            gp=gpar(fontsize=20, fontface=2)))
dev.off()
plot(p)
```


## Numeric inspection 

Calculate standard deviations of the different samples as a numeric indicator of the variability in the data.

```{r}
# Turn the list of dataframes for each iteration into a single dataframe
means.cond.df <- bind_rows(means.cond.list)
aggMeansSE(means.cond.df, c("MeanRT", "Cond", "Region"))
```

